learningRate = 0.02;
inputsX = RetrieveBinaryInputs;
%targetsT = RetrieveBinaryTargets;
targetsT = [1, 1, 1, -1, -1, 1, -1, -1, -1, 1, -1, -1, -1, -1, -1, -1;...
nWeights = 4;
maximumUpdates = 1e5;
numberOfInputs = size(inputsX,1);

   
outputsO = zeros(numberOfInputs,1);
weightsW = -0.2 + 2*0.2 * rand(nWeights,1);
threshold = -1 + 2 * rand(1);
iter = 0;    
iFunction = 6; % Set which function to use as targets

for k = 1:maximumUpdates
    iter = iter + 1;
    mu = randi(numberOfInputs);
    
    outputArgument = b_m(threshold,weightsW,inputsX,mu);
    outputsO(mu) = tanh(outputArgument); % Calculate outputs  
    
    if isequal(sign(outputsO),targetsT(iFunction,:))
        break
    end 
    
    weightChange = dWeights(learningRate,targetsT,inputsX,outputsO,outputArgument,mu,iFunction);
    thresholdChange = dThreshold(learningRate,targetsT,outputsO,outputArgument,mu,iFunction);
    
    weightsW = weightsW + weightChange;
    threshold = threshold + thresholdChange;

end

if isequal(sign(outputsO),targetsT(iFunction,:))
    disp('All inputs classified correctly, function is linearly separable.')
else 
    disp('Inputs not classified correctly, function may not be linearly separable')
end


function weightChange = dWeights(learningRate,targetsT,inputsX,outputsO,outputArgument,mu,func)
    
    weightChange = (targetsT(func,mu) - outputsO(mu)) * (1-(tanh(outputArgument))^2) * transpose(inputsX(mu,:));

    weightChange = learningRate * weightChange;
end

function thresholdChange = dThreshold(learningRate,targetsT,outputsO,outputArgument,mu,func)    

    thresholdChange = -learningRate * (targetsT(func,mu) - outputsO(mu)) * ((1-tanh(outputArgument))^2);

end

function argument = b_m(threshold,weightsW,inputsX,mu)
    
    sumWX = 0;
    for n = 1:4
        sumWX = sumWX + weightsW(n) * inputsX(mu,n);
    end
    argument = 0.5 * (-threshold + sumWX);
end

Second, I recommend that you take a closer look at the critera for convergence from the problem description. Then check your code again and consider what it actually is you are checking inside the training loop as a condition for breaking. It's supposed to halt either after the maximum number of iterations or when all patterns are classified correctly.
